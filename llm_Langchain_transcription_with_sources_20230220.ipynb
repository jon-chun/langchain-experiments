{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain: LLM + YouTube Transcriptions\n",
        "\n",
        "* https://github.com/leegonzales/LangChainExamples\n",
        "\n",
        "Modified/Checked:\n",
        "\n",
        "21 Feb 2023: Jon Chun"
      ],
      "metadata": {
        "id": "WkSrlUKv4Zrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query the YouTube video transcripts, returning timestamps as sources to legitimize the answers by [@m_morzywolek](https://twitter.com/m_morzywolek)"
      ],
      "metadata": {
        "id": "6WFk81JVP4Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "3H-vLLVw85s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First set runtime to GPU"
      ],
      "metadata": {
        "id": "jdwAawIyJ6nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC0p1VRjIlFE",
        "outputId": "4089f9bf-2b29-4512-b41e-8b3c2ffada96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube # For audio downloading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q # Whisper from OpenAI transcription model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zAC6DJ5IwTk",
        "outputId": "8c88ca25-2989-4ea6-fb65-f2589b70e743"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper \n",
        "import pytube "
      ],
      "metadata": {
        "id": "8h_FeO8TI3Zn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set YouTube URL and Get Transcript"
      ],
      "metadata": {
        "id": "IVb3xNbS8-TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.youtube.com/watch?v=UF8uR6Z6KLc&ab_channel=Stanford\"\n",
        "video = pytube.YouTube(url)"
      ],
      "metadata": {
        "id": "eOgbnvXkI50t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = video.streams.get_audio_only()\n",
        "audio.download(filename='tmp.mp3') # Downlods only audio from youtube video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ls2DYRxPJQmw",
        "outputId": "27a1a07f-df7b-46e2-ff5a-2b1f679212c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/tmp.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOZ6sSu1Jgm-",
        "outputId": "871144ca-c8cd-4786-8dfc-cdf034f267bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 107MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# NOTE: 01m20s on 20230221 @ 16:32 Tues for 15m YouTube Video: https://www.youtube.com/watch?v=UF8uR6Z6KLc&ab_channel=Stanford\n",
        "\n",
        "transcription = model.transcribe('/content/tmp.mp3')"
      ],
      "metadata": {
        "id": "DMCQql4AJmaf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = transcription['segments']"
      ],
      "metadata": {
        "id": "HS9GCRIQKogF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def store_segments(segments):\n",
        "  texts = []\n",
        "  start_times = []\n",
        "\n",
        "  for segment in segments:\n",
        "    text = segment['text']\n",
        "    start = segment['start']\n",
        "\n",
        "    # Convert the starting time to a datetime object\n",
        "    start_datetime = datetime.fromtimestamp(start)\n",
        "\n",
        "    # Format the starting time as a string in the format \"00:00:00\"\n",
        "    formatted_start_time = start_datetime.strftime('%H:%M:%S')\n",
        "\n",
        "    texts.append(\"\".join(text))\n",
        "    start_times.append(formatted_start_time)\n",
        "\n",
        "  return texts, start_times"
      ],
      "metadata": {
        "id": "lHVWts6YKuDq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_segments(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4IaERsPKxKu",
        "outputId": "d8d1b8f7-5395-416a-fbb1-63b7c4a12b60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([' This program is brought to you by Stanford University.',\n",
              "  ' Please visit us at stanford.edu.',\n",
              "  ' Thank you.',\n",
              "  \" I'm honored to be with you today for your commencement from one of the finest universities\",\n",
              "  ' in the world.',\n",
              "  \" Truth be told, I never graduated from college and this is the closest I've ever gotten\",\n",
              "  ' to a college graduation.',\n",
              "  ' Today I want to tell you three stories from my life.',\n",
              "  \" That's it.\",\n",
              "  ' No big deal.',\n",
              "  ' Just three stories.',\n",
              "  ' The first story is about connecting the dots.',\n",
              "  ' I dropped out of Reed College after the first six months but then stayed around as a drop-in',\n",
              "  ' for another 18 months or so before I really quit.',\n",
              "  \" So why'd I drop out?\",\n",
              "  ' It started before I was born.',\n",
              "  ' My biological mother was a young unwed graduate student and she decided to put me up for adoption.',\n",
              "  ' She felt very strongly that I should be adopted by college graduates so everything was all',\n",
              "  ' set for me to be adopted at birth by a lawyer and his wife.',\n",
              "  ' Except that when I popped out, they decided at the last minute that they really wanted',\n",
              "  ' a girl.',\n",
              "  ' So my parents, who were on a waiting list, got a call in the middle of the night asking,',\n",
              "  \" we've got an unexpected baby boy.\",\n",
              "  ' Do you want him?',\n",
              "  ' They said, of course.',\n",
              "  ' My biological mother found out later that my mother had never graduated from college',\n",
              "  ' and that my father had never graduated from high school.',\n",
              "  ' She refused to sign the final adoption papers.',\n",
              "  ' She only relented a few months later when my parents promised that I would go to college.',\n",
              "  ' This was the start in my life.',\n",
              "  ' And 17 years later, I did go to college.',\n",
              "  ' But I naively chose a college that was almost as expensive as Stanford.',\n",
              "  \" And all of my working class parents' savings were being spent on my college tuition.\",\n",
              "  \" After six months, I couldn't see the value in it.\",\n",
              "  ' I had no idea what I wanted to do with my life and no idea how college was going to',\n",
              "  ' help me figure it out.',\n",
              "  ' And here I was spending all of the money my parents had saved their entire life.',\n",
              "  ' So I decided to drop out and trust that it would all work out okay.',\n",
              "  ' It was pretty scary at the time, but looking back, it was one of the best decisions I ever',\n",
              "  ' made.',\n",
              "  \" The minute I dropped out, I could stop taking the required classes that didn't interest\",\n",
              "  ' me and begin dropping in on the ones that looked far more interesting.',\n",
              "  \" It wasn't all romantic.\",\n",
              "  \" I didn't have a dorm room, so I slept on the floor in friends' rooms.\",\n",
              "  ' I returned Coke bottles for the five cent deposits to buy food with.',\n",
              "  ' I would walk the seven miles across town every Sunday night to get one good meal a week at',\n",
              "  ' the Hari Krishna Temple.',\n",
              "  ' I loved it.',\n",
              "  ' And much of what I stumbled into by following my curiosity and intuition turned out to be',\n",
              "  ' priceless later on.',\n",
              "  ' Let me give you one example.',\n",
              "  ' Reed College at that time offered perhaps the best calligraphy instruction in the country.',\n",
              "  ' Throughout the campus, every poster, every label on every drawer was beautifully hand',\n",
              "  ' caligraphed.',\n",
              "  \" Because I had dropped out and didn't have to take the normal classes, I decided to take\",\n",
              "  ' a calligraphy class to learn how to do this.',\n",
              "  ' I learned about serif and sans serif typefaces, about varying the amount of space between different',\n",
              "  ' letter combinations, about what makes great typography great.',\n",
              "  \" It was beautiful, historical, artistically subtle in a way that science can't capture,\",\n",
              "  ' and I found it fascinating.',\n",
              "  ' None of this had even a hope of any practical application in my life.',\n",
              "  ' But ten years later, when we were designing the first Macintosh computer, it all came',\n",
              "  ' back to me.',\n",
              "  ' And we designed it all into the Mac.',\n",
              "  ' It was the first computer with beautiful typography.',\n",
              "  ' If I had never dropped in on that single course in college, the Mac would have never',\n",
              "  ' had multiple typefaces or proportionally spaced fonts.',\n",
              "  \" And since Windows just copied the Mac, it's likely that no personal computer would have\",\n",
              "  ' them.',\n",
              "  ' If I had never dropped out, I would have never dropped in on that calligraphy class, and',\n",
              "  ' personal computers might not have the wonderful typography that they do.',\n",
              "  ' Of course, it was impossible to connect the dots looking forward when I was in college.',\n",
              "  ' But it was very, very clear looking backwards ten years later.',\n",
              "  \" Again, you can't connect the dots looking forward.\",\n",
              "  ' You can only connect them looking backwards.',\n",
              "  ' So you have to trust that the dots will somehow connect in your future.',\n",
              "  ' You have to trust in something, your gut, destiny, life, karma, whatever.',\n",
              "  ' Because believing that the dots will connect down the road will give you the confidence',\n",
              "  ' to follow your heart, even when it leads you off the well-worn path.',\n",
              "  ' And that will make all the difference.',\n",
              "  ' My second story is about love and loss.',\n",
              "  ' I was lucky.',\n",
              "  ' I found what I loved to do early in life.',\n",
              "  \" Waz and I started Apple in my parents' garage when I was 20.\",\n",
              "  ' We worked hard, and in ten years Apple had grown from just the two of us in a garage',\n",
              "  ' into a two billion dollar company with over 4,000 employees.',\n",
              "  ' We just released our finest creation, the Macintosh, a year earlier, and I just turned',\n",
              "  ' 30.',\n",
              "  ' And then I got fired.',\n",
              "  ' How can you get fired from a company you started?',\n",
              "  ' Well, as Apple grew, we hired someone who I thought was very talented to run the company',\n",
              "  ' with me.',\n",
              "  ' And for the first year or so, things went well.',\n",
              "  ' But then our visions of the future began to diverge, and eventually we had a falling out.',\n",
              "  ' When we did, our board of directors sided with him.',\n",
              "  ' And so at 30, I was out, and very publicly out.',\n",
              "  ' But it had been the focus of my entire adult life was gone, and it was devastating.',\n",
              "  \" I really didn't know what to do for a few months.\",\n",
              "  ' I felt that I had let the previous generation of entrepreneurs down, that I had dropped',\n",
              "  ' the baton as it was being passed to me.',\n",
              "  ' I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly.',\n",
              "  ' I was a very public failure, and I even thought about running away from the valley.',\n",
              "  ' But something slowly began to dawn on me.',\n",
              "  ' I still loved what I did.',\n",
              "  ' The turn of events at Apple had not changed that one bit.',\n",
              "  \" I'd been rejected, but I was still in love.\",\n",
              "  ' And so I decided to start over.',\n",
              "  \" I didn't see it then, but it turned out that getting fired from Apple was the best thing\",\n",
              "  ' that could have ever happened to me.',\n",
              "  ' The heaviness of being successful was replaced by the lightness of being a beginner again,',\n",
              "  ' less sure about everything.',\n",
              "  ' It freed me to enter one of the most creative periods of my life.',\n",
              "  ' During the next five years, I started a company named Next, another company named Pixar, and',\n",
              "  ' fell in love with an amazing woman who would become my wife.',\n",
              "  \" Pixar went on to create the world's first computer-animated feature film, Toy Story,\",\n",
              "  ' and is now the most successful animation studio in the world.',\n",
              "  ' In a remarkable turn of events, Apple bought Next, and I returned to Apple, and the technology',\n",
              "  \" we developed at Next is at the heart of Apple's current renaissance.\",\n",
              "  ' And Lorraine and I have a wonderful family together.',\n",
              "  \" I'm pretty sure none of this would have happened if I hadn't been fired from Apple.\",\n",
              "  ' It was awful-tasting medicine, but I guess the patient needed it.',\n",
              "  \" Sometimes life's going to hit you in the head with a brick.\",\n",
              "  \" Don't lose faith.\",\n",
              "  \" I'm convinced that the only thing that kept me going was that I loved what I did.\",\n",
              "  \" You've got to find what you love.\",\n",
              "  ' And that is as true for work as it is for your lovers.',\n",
              "  ' Your work is going to fill a large part of your life, and the only way to be truly satisfied',\n",
              "  ' is to do what you believe is great work.',\n",
              "  ' And the only way to do great work is to love what you do.',\n",
              "  \" If you haven't found it yet, keep looking and don't settle.\",\n",
              "  \" As with all matters of the heart, you'll know when you find it.\",\n",
              "  ' And like any great relationship, it just gets better and better as the years roll on.',\n",
              "  \" So keep looking, don't settle.\",\n",
              "  ' My third story is about death.',\n",
              "  ' When I was 17, I read a quote that went something like, if you live each day as if it was your',\n",
              "  \" last, someday you'll most certainly be right.\",\n",
              "  \" It made an impression on me, and since then, for the past 33 years, I've looked in the\",\n",
              "  ' mirror every morning and asked myself, if today were the last day of my life, what I',\n",
              "  ' want to do, what I am about to do today.',\n",
              "  ' And whenever the answer has been no, for too many days in a row, I know I need to change',\n",
              "  ' something.',\n",
              "  \" Remembering that I'll be dead soon is the most important tool I've ever encountered to help\",\n",
              "  ' me make the big choices in life.',\n",
              "  ' As almost everything, all external expectations, all pride, all fear of embarrassment or failure,',\n",
              "  ' these things just fall away in the face of death, leaving only what is truly important.',\n",
              "  ' Remembering that you are going to die is the best way I know to avoid the trap of thinking',\n",
              "  ' you have something to lose.',\n",
              "  ' You are already naked.',\n",
              "  ' There is no reason not to follow your heart.',\n",
              "  ' About a year ago, I was diagnosed with cancer.',\n",
              "  ' I had a scan at 7.30 in the morning, and it clearly showed a tumor on my pancreas.',\n",
              "  \" I didn't even know what a pancreas was.\",\n",
              "  ' The doctors told me this was almost certainly a type of cancer that is incurable and that',\n",
              "  ' I should expect to live no longer than three to six months.',\n",
              "  \" My doctor advised me to go home and get my affairs in order, which is doctor's code\",\n",
              "  ' for prepare to die.',\n",
              "  ' It means to try and tell your kids everything you thought you would have the next ten years',\n",
              "  ' to tell them in just a few months.',\n",
              "  ' It means to make sure everything is buttoned up so that it will be as easy as possible',\n",
              "  ' for your family.',\n",
              "  ' It means to say your goodbyes.',\n",
              "  ' I live with that diagnosis all day.',\n",
              "  ' Later that evening, I had a biopsy where they stuck an endoscope down my throat, through',\n",
              "  ' my stomach and into my intestines, put a needle into my pancreas and got a few cells from',\n",
              "  ' the tumor.',\n",
              "  ' I was sedated, but my wife, who was there, told me that when they viewed the cells under',\n",
              "  ' a microscope, the doctors started crying because it turned out to be a very rare form of pancreatic',\n",
              "  ' cancer that is curable with surgery.',\n",
              "  \" I had the surgery, and thankfully I'm fine now.\",\n",
              "  \" This was the closest I've been to facing death, and I hope it's the closest I get for a few\",\n",
              "  ' more decades.',\n",
              "  ' Having lived through it, I can now say this to you with a bit more certainty than when',\n",
              "  ' death was a useful but purely intellectual concept.',\n",
              "  ' No one wants to die.',\n",
              "  \" Even people who want to go to heaven don't want to die to get there.\",\n",
              "  ' And yet, death is the destination we all share.',\n",
              "  ' No one has ever escaped it.',\n",
              "  ' And that is as it should be, because death is very likely the single best invention of',\n",
              "  ' life.',\n",
              "  \" It's life's change agent.\",\n",
              "  ' It clears out the old to make way for the new.',\n",
              "  ' Right now, the new is you.',\n",
              "  ' But someday, not too long from now, you will gradually become the old and be cleared away.',\n",
              "  \" Sorry to be so dramatic, but it's quite true.\",\n",
              "  \" Your time is limited, so don't waste it living someone else's life.\",\n",
              "  \" Don't be trapped by dogma, which is living with the results of other people's thinking.\",\n",
              "  \" Don't let the noise of others' opinions drown out your own inner voice.\",\n",
              "  ' And most important, have the courage to follow your heart and intuition.',\n",
              "  ' They somehow already know what you truly want to become.',\n",
              "  ' Everything else is secondary.',\n",
              "  ' When I was young, there was an amazing publication called the Whole Earth Catalog, which was',\n",
              "  ' one of the Bibles of my generation.',\n",
              "  ' It was created by a fellow named Stewart Brand, not far from here in Menlo Park, and he brought',\n",
              "  ' it to life with his poetic touch.',\n",
              "  ' This was in the late 60s, before personal computers and desktop publishing, so it was',\n",
              "  ' all made with typewriters, scissors, and Polaroid cameras.',\n",
              "  ' It was sort of like Google in paperback form 35 years before Google came along.',\n",
              "  ' It was idealistic, overflowing with neat tools and great notions.',\n",
              "  ' Stewart and his team put out several issues of the Whole Earth Catalog, and then, when',\n",
              "  ' it had run its course, they put out a final issue.',\n",
              "  ' It was the mid-1970s, and I was your age.',\n",
              "  ' On the back cover of their final issue was a photograph of an early morning country road,',\n",
              "  ' the kind you might find yourself hitchhiking on if you were so adventurous.',\n",
              "  ' Beneath it were the words, stay hungry, stay foolish.',\n",
              "  ' It was their farewell message as they signed off.',\n",
              "  ' Stay hungry, stay foolish.',\n",
              "  ' And I have always wished that for myself.',\n",
              "  ' And now, as you graduate to begin anew, I wish that for you.',\n",
              "  ' Stay hungry, stay foolish.',\n",
              "  ' Thank you all very much.',\n",
              "  ' The preceding program is copyrighted by Stanford University.',\n",
              "  ' Please visit us at stanford.edu.'],\n",
              " ['00:00:00',\n",
              "  '00:00:10',\n",
              "  '00:00:15',\n",
              "  '00:00:27',\n",
              "  '00:00:31',\n",
              "  '00:00:36',\n",
              "  '00:00:44',\n",
              "  '00:00:48',\n",
              "  '00:00:51',\n",
              "  '00:00:52',\n",
              "  '00:00:53',\n",
              "  '00:00:55',\n",
              "  '00:01:00',\n",
              "  '00:01:05',\n",
              "  '00:01:09',\n",
              "  '00:01:12',\n",
              "  '00:01:15',\n",
              "  '00:01:22',\n",
              "  '00:01:26',\n",
              "  '00:01:32',\n",
              "  '00:01:35',\n",
              "  '00:01:37',\n",
              "  '00:01:42',\n",
              "  '00:01:45',\n",
              "  '00:01:47',\n",
              "  '00:01:50',\n",
              "  '00:01:55',\n",
              "  '00:01:59',\n",
              "  '00:02:03',\n",
              "  '00:02:09',\n",
              "  '00:02:13',\n",
              "  '00:02:17',\n",
              "  '00:02:22',\n",
              "  '00:02:27',\n",
              "  '00:02:30',\n",
              "  '00:02:35',\n",
              "  '00:02:36',\n",
              "  '00:02:42',\n",
              "  '00:02:47',\n",
              "  '00:02:51',\n",
              "  '00:02:54',\n",
              "  '00:02:58',\n",
              "  '00:03:04',\n",
              "  '00:03:06',\n",
              "  '00:03:10',\n",
              "  '00:03:14',\n",
              "  '00:03:19',\n",
              "  '00:03:22',\n",
              "  '00:03:23',\n",
              "  '00:03:28',\n",
              "  '00:03:30',\n",
              "  '00:03:33',\n",
              "  '00:03:38',\n",
              "  '00:03:43',\n",
              "  '00:03:45',\n",
              "  '00:03:50',\n",
              "  '00:03:52',\n",
              "  '00:03:58',\n",
              "  '00:04:03',\n",
              "  '00:04:09',\n",
              "  '00:04:12',\n",
              "  '00:04:17',\n",
              "  '00:04:22',\n",
              "  '00:04:23',\n",
              "  '00:04:25',\n",
              "  '00:04:29',\n",
              "  '00:04:33',\n",
              "  '00:04:37',\n",
              "  '00:04:41',\n",
              "  '00:04:49',\n",
              "  '00:04:54',\n",
              "  '00:04:58',\n",
              "  '00:05:02',\n",
              "  '00:05:06',\n",
              "  '00:05:09',\n",
              "  '00:05:12',\n",
              "  '00:05:16',\n",
              "  '00:05:21',\n",
              "  '00:05:26',\n",
              "  '00:05:30',\n",
              "  '00:05:38',\n",
              "  '00:05:43',\n",
              "  '00:05:44',\n",
              "  '00:05:47',\n",
              "  '00:05:51',\n",
              "  '00:05:56',\n",
              "  '00:05:59',\n",
              "  '00:06:04',\n",
              "  '00:06:06',\n",
              "  '00:06:08',\n",
              "  '00:06:12',\n",
              "  '00:06:17',\n",
              "  '00:06:18',\n",
              "  '00:06:20',\n",
              "  '00:06:25',\n",
              "  '00:06:28',\n",
              "  '00:06:33',\n",
              "  '00:06:38',\n",
              "  '00:06:40',\n",
              "  '00:06:45',\n",
              "  '00:06:47',\n",
              "  '00:06:54',\n",
              "  '00:06:58',\n",
              "  '00:07:01',\n",
              "  '00:07:04',\n",
              "  '00:07:07',\n",
              "  '00:07:11',\n",
              "  '00:07:14',\n",
              "  '00:07:18',\n",
              "  '00:07:20',\n",
              "  '00:07:25',\n",
              "  '00:07:27',\n",
              "  '00:07:31',\n",
              "  '00:07:36',\n",
              "  '00:07:39',\n",
              "  '00:07:44',\n",
              "  '00:07:49',\n",
              "  '00:07:55',\n",
              "  '00:07:59',\n",
              "  '00:08:03',\n",
              "  '00:08:07',\n",
              "  '00:08:12',\n",
              "  '00:08:16',\n",
              "  '00:08:17',\n",
              "  '00:08:21',\n",
              "  '00:08:24',\n",
              "  '00:08:27',\n",
              "  '00:08:32',\n",
              "  '00:08:34',\n",
              "  '00:08:38',\n",
              "  '00:08:43',\n",
              "  '00:08:47',\n",
              "  '00:08:51',\n",
              "  '00:09:04',\n",
              "  '00:09:08',\n",
              "  '00:09:14',\n",
              "  '00:09:20',\n",
              "  '00:09:25',\n",
              "  '00:09:30',\n",
              "  '00:09:33',\n",
              "  '00:09:38',\n",
              "  '00:09:40',\n",
              "  '00:09:44',\n",
              "  '00:09:47',\n",
              "  '00:09:54',\n",
              "  '00:10:00',\n",
              "  '00:10:05',\n",
              "  '00:10:07',\n",
              "  '00:10:09',\n",
              "  '00:10:13',\n",
              "  '00:10:17',\n",
              "  '00:10:22',\n",
              "  '00:10:25',\n",
              "  '00:10:30',\n",
              "  '00:10:35',\n",
              "  '00:10:41',\n",
              "  '00:10:43',\n",
              "  '00:10:48',\n",
              "  '00:10:51',\n",
              "  '00:10:55',\n",
              "  '00:10:57',\n",
              "  '00:11:00',\n",
              "  '00:11:03',\n",
              "  '00:11:08',\n",
              "  '00:11:13',\n",
              "  '00:11:14',\n",
              "  '00:11:19',\n",
              "  '00:11:25',\n",
              "  '00:11:28',\n",
              "  '00:11:40',\n",
              "  '00:11:44',\n",
              "  '00:11:46',\n",
              "  '00:11:50',\n",
              "  '00:11:55',\n",
              "  '00:11:57',\n",
              "  '00:12:01',\n",
              "  '00:12:05',\n",
              "  '00:12:07',\n",
              "  '00:12:13',\n",
              "  '00:12:14',\n",
              "  '00:12:16',\n",
              "  '00:12:19',\n",
              "  '00:12:22',\n",
              "  '00:12:27',\n",
              "  '00:12:32',\n",
              "  '00:12:37',\n",
              "  '00:12:42',\n",
              "  '00:12:46',\n",
              "  '00:12:50',\n",
              "  '00:12:55',\n",
              "  '00:12:57',\n",
              "  '00:13:14',\n",
              "  '00:13:17',\n",
              "  '00:13:22',\n",
              "  '00:13:25',\n",
              "  '00:13:30',\n",
              "  '00:13:34',\n",
              "  '00:13:39',\n",
              "  '00:13:44',\n",
              "  '00:13:49',\n",
              "  '00:13:52',\n",
              "  '00:13:57',\n",
              "  '00:14:03',\n",
              "  '00:14:08',\n",
              "  '00:14:13',\n",
              "  '00:14:16',\n",
              "  '00:14:19',\n",
              "  '00:14:23',\n",
              "  '00:14:28',\n",
              "  '00:14:31',\n",
              "  '00:14:56',\n",
              "  '00:15:00'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts, start_times = store_segments(res)"
      ],
      "metadata": {
        "id": "__-hrw_6LYsu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create LangChain: LLM + FAISS Dense Vector Similiarity Search"
      ],
      "metadata": {
        "id": "IFmcr2kX9HuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "7auAzAfXL1V7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5a838b-1fbb-4391-b21b-151ccf5da8a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.92-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.8/dist-packages (from langchain) (3.8.4)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.8/dist-packages (from langchain) (2.25.1)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.8/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.21.6)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from langchain) (8.2.1)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.4.46)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.8/dist-packages (from langchain) (1.10.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.0.1)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.8/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Collecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2->langchain) (4.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, marshmallow-enum, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.7 langchain-0.0.92 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 typing-inspect-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "EMG0TDLoL5rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d73045-3883-429d-f31f-c239c6e8bdb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.5-py3-none-any.whl size=67620 sha256=354042d432c3cfb1c781cba81b88e4c639f1d49948d3b37084128eaeaa350da3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/47/99/8273a59fbd59c303e8ff175416d5c1c9c03a2e83ebf7525a99\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade faiss-gpu==1.7.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TNi-J7FMAlT",
        "outputId": "5aa22cae-e34c-4b62-8a91-e89a49c417b4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu==1.7.1\n",
            "  Downloading faiss_gpu-1.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chains import VectorDBQAWithSourcesChain\n",
        "from langchain import OpenAI\n",
        "import openai\n",
        "import faiss"
      ],
      "metadata": {
        "id": "sJvI6zAcLpDZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set OpenAI API Key"
      ],
      "metadata": {
        "id": "FfdnIijg9Y4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Signup for an OpenAPI API Key at www.openai.com/api"
      ],
      "metadata": {
        "id": "4VJD5efg8MBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass('Enter your OpenAI key: ')\n",
        "# print(f'OPENAI_API_KEY is: {OPENAI_API_KEY}')\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkHoYij_55yO",
        "outputId": "f2459125-aa86-455c-c21d-236f1c9b8553"
      },
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1500, separator=\"\\n\")\n",
        "docs = []\n",
        "metadatas = []\n",
        "for i, d in enumerate(texts):\n",
        "    splits = text_splitter.split_text(d)\n",
        "    docs.extend(splits)\n",
        "    metadatas.extend([{\"source\": start_times[i]}] * len(splits))\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "6ZylCKSqMLm-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = FAISS.from_texts(docs, embeddings, metadatas=metadatas)\n",
        "faiss.write_index(store.index, \"docs.index\")"
      ],
      "metadata": {
        "id": "VScsZ_MzMRuv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = VectorDBQAWithSourcesChain.from_llm(llm=OpenAI(temperature=0), vectorstore=store)"
      ],
      "metadata": {
        "id": "tk-fzMBgMt9g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach GDrive for permanent storage\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2aPjaLB_Gps6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521dc151-5f35-431d-939e-c910107051ee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seven Q&A Test Questions"
      ],
      "metadata": {
        "id": "rBpl-Th6Ck42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First Run will download LangChain components (vocab, merges, tokenizer, config)\n",
        "\n",
        "result = chain({\"question\": \"How old was Steve Jobs when started Apple?\"})"
      ],
      "metadata": {
        "id": "8JUgPLpnNOvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8762388d-43be-40b6-9412-2d156ad9d343"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1576 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #1\n",
        "\n",
        "print(f\"Answer: {result['answer']}  Sources: {result['sources']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du4gg4C1NX_h",
        "outputId": "e15b7272-57da-4a74-dbd7-2ff2c7cff2a9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  Steve Jobs was 20 when he started Apple.\n",
            "  Sources: 00:05:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #2\n",
        "\n",
        "my_question = \"Where was Apple started?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLKkzqaq-FXD",
        "outputId": "501949cd-bbe6-4f3d-8e1e-10a2e560950c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1605 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: Where was Apple started?\n",
            "\n",
            "\n",
            "Answer:  Apple was started in Waz and Steve Jobs' parents' garage.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:05:47, 00:05:51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #3\n",
        "\n",
        "my_question = \"Who were the first employees of Apple?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epT8WI9z-FQ1",
        "outputId": "a06ef0e5-0f50-4136-ba9c-ed1608823c19"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: Who were the first employees of Apple?\n",
            "\n",
            "\n",
            "Answer:  The first employees of Apple were Steve Wozniak and Steve Jobs.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:05:47, 00:05:51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #4\n",
        "\n",
        "my_question = \"What makes a great entrepreneur?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0BNrMp-KTe",
        "outputId": "52fd4ede-bbbd-4a1a-b9bf-95e415f0df72"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: What makes a great entrepreneur?\n",
            "\n",
            "\n",
            "Answer:  A great entrepreneur has the courage to follow their heart and intuition.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:12:46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #5\n",
        "\n",
        "my_question = \"How do you deal with the fear of failure?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "297lwDQ1-LUP",
        "outputId": "99bcae96-e82e-4472-d4d7-a1241aa88a42"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1598 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: How do you deal with the fear of failure?\n",
            "\n",
            "\n",
            "Answer:  To deal with the fear of failure, have faith and believe that the dots will connect down the road, which will give you the confidence.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:05:21, 00:08:16, 00:09:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #6\n",
        "\n",
        "my_question = \"What is the most important goal in life?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsB6SsbdBwOQ",
        "outputId": "821d3ca3-c99a-45be-e028-4542f6861fbb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: What is the most important goal in life?\n",
            "\n",
            "\n",
            "Answer:  The most important goal in life is to have the courage to follow your heart and intuition.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:12:46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #7\n",
        "\n",
        "my_question = \"Do you fear failure?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGtnUcIhCByR",
        "outputId": "df496e86-5db6-4443-c4bf-cf4e63a7157f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: Do you fear failure?\n",
            "\n",
            "\n",
            "Answer:  I don't know.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:09:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q&A Test #8\n",
        "\n",
        "my_question = \"How do you deal with people who doubt you?\"\n",
        "result = chain({\"question\": my_question})\n",
        "\n",
        "print(f\"\\n\\nQuestion: {my_question}\")\n",
        "print(f\"\\n\\nAnswer: {result['answer']}\")\n",
        "\n",
        "# NOTE: type(result['sources']) = str in format \"timestamp, timestamp\"\n",
        "print(f\"\\nBased on Time Stamp: {result['sources']}\")  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wltF7_M2CBhY",
        "outputId": "8a2cd91f-1cb2-4655-dc46-079cf8489100"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1592 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: How do you deal with people who doubt you?\n",
            "\n",
            "\n",
            "Answer:  Don't lose faith and don't let the noise of others' opinions drown out your own inner voice.\n",
            "\n",
            "\n",
            "Based on Time Stamp: 00:08:16, 00:12:42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loop over This Section to Repeatedly Ask Questions based on Transcript"
      ],
      "metadata": {
        "id": "GQFUY3ZO93lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = input(\"Enter a question to get an answer based upon the YouTube transcript: \")\n",
        "print(f'\\nYour question: {my_question}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al2HY9607QQz",
        "outputId": "62332a68-b4d1-45c3-f336-72c89d0e5bdf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a question to get an answer based upon the YouTube transcript: What makes a great entrepreneur?\n",
            "\n",
            "Your question: What makes a great entrepreneur?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain({\"question\": my_question})\n",
        "print(f\"Answer: {result['answer']}  Sources: {result['sources']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5zA3Bft7lot",
        "outputId": "53bfcd28-0687-45f6-f62f-419bcfa63d2b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1578 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:  A great entrepreneur has the courage to follow their heart and intuition.\n",
            "  Sources: 00:12:46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5o2u8VPl7sYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}